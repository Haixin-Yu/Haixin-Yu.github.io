---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append:
site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append:
site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "
google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üë®‚Äçüéì About Me

Hello everyone, welcome to my personal homepage!

My research focuses on robotic perception, learning and planning, with
applications mainly on manipulation tasks for
home service robots.

Previously, I received my Master's degree from Tsinghua University in 2024 and
my Bachelor's degree from Northeastern University in 2021.

[//]: # (My research interest includes neural machine translation and computer vision. I)

[//]: # (have published more than 100 papers at)

[//]: # (the top international AI conferences with)

[//]: # (total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google)

[//]: # (scholar citations <strong><span id='total_cit'>260000+</span></strong></a> &#40;You)

[//]: # (can also use google scholar)

[//]: # (badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>&#41;.)

[//]: # (# üî• News)

[//]: # ()

[//]: # (- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit.)

[//]: # (  Vivamus ornare aliquet ipsum, ac tempus)

[//]: # (  justo dapibus sit amet.)

[//]: # (- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit.)

[//]: # (  Vivamus ornare aliquet ipsum, ac tempus)

[//]: # (  justo dapibus sit amet.)

# üìù Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">T-RO</div><img src='images/PIC2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Visual‚ÄìTactile Fusion for Transparent Object Grasping in Complex Backgrounds**](https://ieeexplore.ieee.org/abstract/document/10175024)


Li Shoujie\*, **Yu Haixin**\*, Ding Wenbo, Liu Houde, Ye Linqi, Xia Chongkun,
Wang Xueqian, Zhang Xiaoping. **(Equal contribution)** 

 IEEE Transactions on Robotics(T-RO), 2023. (JCR Q1, IF=10.5)

[//]: # (**Project**)

[//]: # ()
[//]: # (- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare)

[//]: # ()
[//]: # (  aliquet ipsum, ac tempus justo dapibus sit)

[//]: # ()
[//]: # (  amet.)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RA-L</div><img src='images/PIC1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**TGF-Net: Sim2Real Transparent Object 6D Pose Estimation Based on Geometric Fusion**](https://ieeexplore.ieee.org/abstract/document/10103597)

**Haixin Yu**, Shoujie Li, Houde Liu, Chongkun Xia, Wenbo Ding, and Bin Liang. 

IEEE Robotics and Automation Letters(RA-L), 2023. (JCR Q1, IF=5.3)

[//]: # ([**Project**]&#40;https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC&#41; <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>)

[//]: # (- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare)

[//]: # (  aliquet ipsum, ac tempus justo dapibus sit)

[//]: # (  amet.)


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA</div><img src='images/PIC3.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover**](https://arxiv.org/abs/2408.14997)

Ran Yu\*, **Haixin Yu**\*, Shoujie Li, Yan Huang, Ziwu Song, Wenbo Ding. **(Equal contribution)**

IEEE International Conference on Robotics and Automation(ICRA), 2025

[//]: # ([**Project**]&#40;https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC&#41; <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>)

[//]: # (- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare)

[//]: # (  aliquet ipsum, ac tempus justo dapibus sit)

[//]: # (  amet.)


</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">T-RO</div><img src='images/PIC4.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**M3Tac: A Multispectral Multimodal Visuotactile Sensor With Beyond-Human Sensory Capabilities**](https://ieeexplore.ieee.org/abstract/document/10682561)

Shoujie Li, **Haixin Yu**, Guoping Pan, Huaze Tang, Jiawei Zhang, Linqi Ye,
Xiao-Ping Zhang, and Wenbo Ding.
IEEE Transactions on Robotics(T-RO), 2024. (JCR Q1, IF=10.5)

[//]: # ([**Project**]&#40;https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC&#41; <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>)

[//]: # (- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare)

[//]: # (  aliquet ipsum, ac tempus justo dapibus sit)

[//]: # (  amet.)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Soft Robotics</div><img src='images/PIC5.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**JamTac: A Tactile Jamming Gripper for Searching and Grasping in Low-Visibility Environments**](https://www.liebertpub.com/doi/abs/10.1089/soro.2022.0134)

Shoujie Li, Linqi Ye, **Haixin Yu**, Xianghui Yin, Chongkun Xia, Wenbo Ding, Xueqian
Wang, and Bin Liang. 

Soft Robotics, 2023. (JCR Q1, IF=6.1)

[//]: # ([**Project**]&#40;https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC&#41; <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>)

[//]: # (- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare)

[//]: # (  aliquet ipsum, ac tempus justo dapibus sit)

[//]: # (  amet.)

</div>
</div>

[//]: # (# üìù Patents)



# üéñ Honors and Awards

- *2023.10* Tsinghua University First-Class Scholarship
- *2023.10* 2023 Shenzhen Excellent Science and Technology Paper
- *2022.10* Tsinghua University Second-Class Scholarship
- *2022.08* The Second Prize in the 4th China Graduate Robotics Innovation Design Competition
- *2021.06* Northeastern University Outstanding Graduate Award
- *2020.10* Outstanding student of Northeastern University
- *2020.10* Northeastern University Second-Class Scholarship
- *2020.04* Meritorious Winner(First Prize) of Mathematical Contest In Modeling(MCM/ICM)
- *2019.12* Chinese National Scholarship
- *2019.10* Outstanding student of Northeastern University
- *2019.10* Northeastern University First-Class Scholarship
- *2019.04* Northeastern University Xianggang Yucai Scholarship
- *2018.10* Northeastern University First-Class Scholarship
- *2018.10* Outstanding student of Northeastern University
  

# üìñ Educations

- *2021.09 - 2024.06*, Master, Tsinghua University, Beijing, China.
- *2017.09 - 2021.06*, Undergraduate, Northeastern University, Shenyang, China.

[//]: # (# üí¨ Invited Tals)

[//]: # ()
[//]: # (- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus)

[//]: # (  ornare aliquet ipsum, ac tempus justo)

[//]: # (  dapibus sit amet.)

[//]: # (- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus)

[//]: # (  ornare aliquet ipsum, ac tempus justo)

[//]: # (  dapibus sit amet. \| [\[video\]]&#40;https://github.com/&#41;)

[//]: # ()
[//]: # (# üíª Internships)

[//]: # ()
[//]: # (- *2019.05 - 2020.02*, [Lorem]&#40;https://github.com/&#41;, China.)